---
author: ""
date: ""
title: "Analysis of Sport Team Colors, Part I"
output:
  html_document:
    toc: false
---

```{r setup, include = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(
  echo = TRUE,
  # include = FALSE,
  # cache = TRUE,
  # results = "markdown",
  results = "hide",
  # fig.align = "center",
  # fig.show = "asis",
  fig.width = 6,
  fig.height = 6,
  # out.width = 6,
  # out.height = 6,
  warning = FALSE,
  message = FALSE
)

```

When working with the [`ggplot2`](http://ggplot2.org/) package, I often find
myself playing around with colors for more time than I probably should be.
I think that this is because I know that
the right color scheme can greatly enhance the information that a plot portrays; 
and, conversely, choosing
an uncomplementary palette can suppress the message of an otherwise good visualization.

With that said, I wanted to take a look at the presence of colors in the
sports realm.
I think some fun insight can be made from some relatively basic analysis of
colors used by individual teams, among teams in a given sport, etc.
(Some people have done some relatively technical research on this topic, such as studying
the possible effects of color on fan (and player) perception of teams.)

## Setup

```{r packages}
# Comment out the packages whose functions will be used explicitly via the "pkg::func" syntax.
library("dplyr")
# library("tidyr")
# library("purrr")
# library("stringr")
library("teamcolors")
# library("nbastatR")
# library("nflscrapR")
library("ggplot2")
# library("UpSetR")
# library("factoextra")
# library("NbClust")
# library("viridis)
```

The data that I'll use comes from the 
[{teamcolors} R package](https://github.com/beanumber/teamcolors), 
which itself is sourced from
[Jim Nielsen's website of the same namesake](http://jim-nielsen.com/teamcolors/).
This data set provides color information from teams from 
six professional sports leagues:

+ EPL (European futbol), 
+ MLB (baseball), 
+ MLS (American soccer), 
+ NBA (basketball), 
+ NFL (American football), and
+ NHL (hockey).

(Only the EPL is a non-American league).
It lists up to four colors for each team.

```{r teamcolors}
teamcolors::teamcolors
```

Putting this data in a "tidy" format is rather straightforward. [^fn_munging]
Note that I use the name `ord` to represent "ordinality" of the color--that is,
primary, secondary, tertiary, or quaternary.

[^fn_munging]:
The fact that the data comes in an easy-to-work-with format comes as a relief
to those of us used to having to clean raw data tediously.

```{r}
colors_tidy <-
  teamcolors::teamcolors %>%
  tidyr::gather(ord, hex, -name, -league)
```


## Exploratory Data Analysis (EDA)

Here's a fairly rough visualizaton of all the colors in this data set.

```{r viz_colors_all, echo = FALSE}
pull_distinctly <- function(data, col) {
  col <- rlang::enquo(col)
  data %>%
    distinct(!!col) %>%
    arrange(!!col) %>%
    pull(!!col)
}

hex_unique <-
  colors_tidy %>% pull_distinctly(hex)

# convert_hex2dec <- function(hex = NULL) {
#   strtoi(stringr::str_replace(hex, "#", ""), base = 16L)
# }

ord_nums <-
  tibble::tibble(
    ord = c("primary", "secondary", "tertiary", "quaternary"),
    ord_num = as.integer(c(1, 2, 3, 4))
  )

tm_nums <-
  teamcolors::teamcolors %>%
  group_by(league) %>%
  mutate(name_num = row_number(desc(name))) %>%
  ungroup() %>% 
  select(name, league, name_num)

lgs <-
  teamcolors::teamcolors %>%
  pull_distinctly(league)

viz_theme_base <-
  teplot::theme_te() +
  theme(
    legend.position = "none",
    # panel.background = element_rect(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_text(angle = 90)
  )
viz_labs_base <-
  labs(x = NULL, y = NULL)
lab_lgs <- stringi::stri_replace_last_fixed(paste(toupper(lgs), collapse = ", "), ", ", ", and ")
lab_base_suffix <-
  paste0(" for All Teams in the ", lab_lgs)

viz_colors_all <-
  colors_tidy %>%
  left_join(ord_nums, by = "ord") %>% 
  left_join(tm_nums, by = c("league", "name")) %>% 
  ggplot(aes(x = name_num, y = ord_num)) +
  geom_tile(aes(fill = hex)) +
  scale_fill_manual(values = hex_unique) +
  facet_wrap(~league, scales = "free", labeller = labeller(league = toupper)) +
  viz_theme_base +
  theme(panel.background = element_rect(), axis.text.y = element_blank()) +
  viz_labs_base +
  labs(
    title = paste0("Colors", lab_base_suffix),
    caption = paste0("Colors are stacked for each individual team.\n",
                     "Source: {teamcolors} R package."))
viz_colors_all
```

### Color Brightness

Note that there quite a few teams without a full set of four colors
(and some without a third or even second color).

```{r iviz_colors_nas_bylg, echo = FALSE}
viz_colors_nas_bylg <-
  teamcolors::teamcolors %>%
  group_by(league) %>%
  summarize_at(vars(ends_with("ary")), funs(sum(is.na(.)))) %>% 
  ungroup() %>% 
  tidyr::gather(ord, value, -league) %>%
  mutate(ord = factor(ord, levels = ord_nums$ord)) %>% 
  ggplot(aes(x = ord, y = value)) +
  geom_col(aes(group = league, fill = league), position = "dodge") +
  teplot::scale_fill_te() +
  viz_theme_base +
  theme(axis.text.x = element_text(angle = 45), legend.position = "right") +
  viz_labs_base +
  labs(title = paste0("Missing Colors", lab_base_suffix),
       subtitle = "Count by League and Ordinality")
viz_colors_nas_bylg
```

```{r colors_pct_nas}
colors_pct_nas <-
  colors_tidy %>%
  count(league, is_na = is.na(hex), sort = TRUE) %>%
  filter(is_na) %>%
  select(-is_na) %>%
  left_join(
    teamcolors::teamcolors %>%
      count(league, sort = TRUE) %>%
      rename(total = n) %>%
      mutate(total = as.integer(4 * total)),
    by = "league"
  ) %>%
  mutate(n_pct = 100 * n / total)
colors_pct_nas
```

Both the visualization and the above tabulation indicate that the MLB is missing
the most colors (on a per-team basis). 
Perhaps this suggest that is the most "dull" sports league. [^fn_mlb_dull]
The NFL is on the other end of the spectrum (pun intended), with only 1.5 %
of missing color values. Is it a coincidence that the
[NFL is the most popular sport in the U.S.](http://news.gallup.com/poll/224864/football-americans-favorite-sport-watch.aspx) 
by a wide margin? [^fn_nfl_notdull]

[^fn_mlb_dull]:
In fact,
the current consensus among sports fans is that the 
[MLB has a decaying fan-base in the U.S. because it is failing to attract younger fans](https://www.huffingtonpost.com/laura-hanby-hudgens/the-decline-of-baseball-a_b_9630782.html). 
This opinion is typically based
on conjectures about the game's slow pace, but, who knows, maybe colors
also has something to do with it! (I'm kidding. I pride myself in guarding against the
[correlation-equals-causation fallacy](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation).)

[^fn_nfl_notdull]:
(Again, in case you think I'm serious, let me be clear--yes, it is most likely a coincidence.)

My subjective indictment of MLB as dull is certainly unfair and unquantitative.
Does "dull" refer to 
[hue, lightness, brightness, etc.](https://en.wikipedia.org/wiki/Color_appearance_model#Color_appearance_parameters)?

For the sake of argument, 
let's say that I want to interpret dullness as 
["brightness"](https://en.wikipedia.org/wiki/Brightness)--the arithmetic mean
of the [red-green-blue](https://en.wikipedia.org/wiki/RGB_color_model) (rgb) values of a given color.
To rank the leagues by brightness, I can
take the average of the rgb values (derived from the hex values) across all colors
for all teams in each league. The resulting values--where a lower value indicates a darker color, 
and a higher value indicates a brighter color--provide a fair measure upon which
each league's aggregate color choices can be judged. [^fn_technical_notes]


[^fn_technical_notes]:
_Technical Notes:_
+ I put this computation in a function because I perform the same actions multiple times.
This practice complies with the [DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself) principle.
+ I was unable to get `grDevices::colo2rgb()` (and some other custom functions
used elsewhere) to work in a vectorized manner, so I created a function (`add_rgb_cols()`) to do so.
I believe the problem is that `grDevices::colo2rgb()` returns a matrix instead of a single value.
+ Additionally, despite only using one element in the returned list here, I wrote
the function to return a list of results
because I was inspecting the different sets of results during code development.
+ Finally, I rescale each rgb value to a value between 0 and 1--rgb is typically expressed on 
a 0 to 255 scale--in order to make the final values more interpretable.


```{r colors_rgb}
add_rgb_cols <- function(data) {
  data %>%
    pull(hex) %>%
    grDevices::col2rgb() %>%
    t() %>%
    tibble::as_tibble() %>%
    bind_cols(data, .) 
}

rank_leagues_byrgb <- function(data = NULL) {
  colors_rgb <-
    data %>%
    add_rgb_cols() %>%
    select(-hex) %>%
    arrange(league, name)
  
  colors_rgb_bynm_bylg <-
    colors_rgb %>%
    mutate_at(vars(red, green, blue), funs(. / 255)) %>%
    group_by(name, league) %>%
    summarize_at(vars(red, green, blue), funs(mean)) %>%
    ungroup() %>%
    tidyr::gather(rgb, value, red, green, blue) %>%
    group_by(name, league) %>%
    summarize_at(vars(value), funs(mean, sd)) %>%
    ungroup() %>%
    arrange(league, mean)
  
  colors_rgb_bylg <-
    colors_rgb_bynm_bylg %>%
    group_by(league) %>%
    summarize_at(vars(mean, sd), funs(mean)) %>%
    ungroup() %>%
    arrange(mean)
  colors_rgb_bylg
}

colors_tidy_nona <-
  colors_tidy %>%
  filter(!is.na(hex))

colors_tidy_nona %>% 
  rank_leagues_byrgb() %>%
  arrange(mean)
```

This calculation proves what we might have guessed by inspection--the NHL actually has the darkest colors.
In fact, it seems that the NHL's "darkness" is most prominent in the primary colors
of the teams in the league.

```{r colors_rgb_bylg_pri}
colors_tidy_nona %>% 
  filter(ord == "primary") %>% 
  rank_leagues_byrgb() %>% 
  arrange(mean)
```

On the other hand, the NBA and the two soccer leagues (the MLS and the EPL) stand
out as the leagues with the most "bright" colors.

Finally, just by inspection, it seems like their is a unusual pattern where a disproportionate
number of teams in the
MLS, NBA, and NFL have shades of gray as their tertiary colors. Using the same function
as before, it can be shown indirectly through a low standard deviation value that
there is not much variation in this color.


```{r colors_rgb_bylg_ter}
colors_tidy_nona %>% 
  filter(ord == "tertiary") %>% 
  rank_leagues_byrgb() %>%
  arrange(sd)
```

### Common Colors

Using a slightly customzied version of the `plotrix::color.id()` function,
I can attempt to identify common colors (by name) from the hex values.

```{r color_functions}
# Reference:
# + plotrix::color.id
color_id <- function(hex, set = grDevices::colors()) {
  c2 <- grDevices::col2rgb(hex)
  coltab <- grDevices::col2rgb(set)
  cdist <- apply(coltab, 2, function(z) sum((z - c2)^2))
  set[which(cdist == min(cdist))]
}

identify_color_name <- function(col = NULL, set = grDevices::colors()) {
  col %>%
    # purrr::map(plotrix::color.id) %>% 
    purrr::map(~color_id(.x, set)) %>% 
    purrr::map_chr(~.[1]) %>% 
    stringr::str_replace_all("[0-9]", "")
}
```

```{r colors_rnbw_hex_add, eval = FALSE}
# colors_rnbw_hex_add <-
#   # paste("#", c(paste(rep(LETTERS[1:6], 6), collapse = "")))
```

I'll bin the possible colors into a predefined set. (If a binning strategy
is not implemented, one ends up with a more sparse, less meaningful grouping of colors.)
This set consists of the "rainbow" colors, as well as black, white, and two shades of grey.

```{r colors_rnbw}
colors_rnbw_hex <-
  c(
    stringr::str_replace_all(grDevices::rainbow(16), "FF$", ""),
    "#FFFFFF",
    "#EEEEEE",
    "#AAAAAA",
    "#000000"
  )
colors_rnbw <- identify_color_name(colors_rnbw_hex)
par(mfrow = c(1, 2))
scales::show_col(colors_rnbw_hex)
scales::show_col(colors_rnbw)
par(mfrow = c(1, 1))
title(main = "Names of Rainbow Hex Colors from `grDevices::rainbow()`")
```

Now, with the setup out of the way, I can easily compute the names of each color
and identify the most common colors overall, as well as the most common
primary and secondary colors.

```{r colors_named}
add_color_nm_col <- function(data, rename = TRUE) {
  out <-
    data %>%
    pull(hex) %>%
    identify_color_name(set = colors_rnbw) %>% 
    tibble::as_tibble() %>% 
    bind_cols(data, .)
  
  if(rename) {
    out <-
      out %>% 
      rename(color_nm = value)
  }
  out
}

colors_named <-
  colors_tidy_nona %>%
  add_color_nm_col()

colors_named %>%
  count(color_nm, sort = TRUE)
colors_named %>%
  count(ord, color_nm, sort = TRUE) %>% 
  filter(ord %in% c("primary", "secondary")) %>% 
  group_by(ord) %>% 
  mutate(rank_byord = row_number(desc(n))) %>% 
  do(head(., 5))
```

Of course, a good visualization to accompany a result set is appreciated.
Given the "set" nature of the data set, I think that
the [`UpSetR`](https://github.com/hms-dbmi/UpSetR) package is very useful here--it can be used to generate
distinctive graphs for set-related data. [^fn_upsetr] 

Neglecting the color black, which is unsuprisingly the most common color,
red has the highest count. (Consequently, it is deserving of use as the fill for the bars
in the following plot). [^fn_upsetr_customization] On the other hand, it's a bit
suprising to me that blue, nor its its brethren in `cyan` and `deepskyblue`, isn't among the top 2 or 3.
One might argue that the three shades of blue inherently cause classification
to be more sparse for it, but this does not seem to suppress the prominence of red,
which also has two sister colors in `orangered` and `darkpink`.

[^fn_upsetr]:
After learning about the [`UpSetR`](https://github.com/hms-dbmi/UpSetR) package recently,
I'm glad to finally have a use-case to use it!

[^fn_upsetr_customization]:
Unfortuantely, it seems
that customizing the colors
for each set is not straightforward, so I did not do it.

```{r colors_sets, echo = FALSE}
ords <- colors_tidy %>% pull_distinctly(ord)
color_nm_na <- "none"
colors_named_complete <-
  colors_named %>% 
  mutate(ord = factor(ord, levels = ords)) %>% 
  select(-hex, -league) %>% 
  tidyr::complete(name, ord, fill = list(color_nm = color_nm_na)) %>%
  tidyr::spread(ord, color_nm)
colors_named_tidy <-
  colors_named_complete %>%
  tidyr::gather(ord, color_nm, -name)

# + Reference:
# https://www.cultureofinsight.com/blog/2018/01/25/2018-01-25-visualising-twitter-follower-overlap/.
nms <- colors_named_tidy %>% pull_distinctly(name)
colors_nms <- colors_named_tidy %>% pull_distinctly(color_nm)

colors_sets <-
  colors_nms %>%
  purrr::map_dfc(~ ifelse(nms %in% filter(colors_named_tidy, color_nm == .x)$name,
                          1,
                          0) %>%
                   as.data.frame()) %>%
  `colnames<-`(colors_nms) %>% 
  mutate_all(as.integer)
colors_sets %>% tibble::as_tibble()
```

```{r viz_colors_sets, echo = FALSE}
colors_nms_exclude <-
  colors_named %>% 
  count(color_nm, sort = TRUE) %>% 
  filter(n <= 5) %>% 
  pull(color_nm) %>% 
  c(color_nm_na)
colors_nms_include <-
  setdiff(colors_nms, colors_nms_exclude)

num_intersects <- 10
viz_colors_sets <-
  UpSetR::upset(
    colors_sets %>% select(one_of(c(colors_nms_include))),
    nsets = length(colors_nms_include),
    nintersects = num_intersects,
    main.bar.color = "red",
    mainbar.y.label = "Color Intersections",
    sets.x.label = "Overall Count",
    # text.scale = c(rep(1.3, length(colors_nms_include)), 1),
    mb.ratio = c(0.6, 0.4),
    order.by = "freq"
  )
```

### Color Clustering

Aside from set analysis, this data set seems prime for 
[unsupervised learning](https://en.wikipedia.org/wiki/Unsupervised_learning), and,
more specifically, [clustering](https://en.wikipedia.org/wiki/Cluster_analysis).
While analysis of the rgb values of the colors can be done (and is actually
what I tried initially), the results are not as interpretable as I would
like it them to be due to the >2-dimensionality nature of such a method. As an alternative,
I determined that ["hue"](https://en.wikipedia.org/wiki/Hue) serves
as a reasonable all-in-one measure of the "essence" of a color. It
is a radial type of value--that is, its value can
range from 0 to 360 (where red is 0 green is 120, blue is 240). [^fn_hue]

[^fn_hue]:
Red is also 360.

To go along with hue, the ordinality of each color with respect to each team
(i.e. primary = 1, secondary = 2, etc.) constitutes a worthwhile secondary feature.
Because most teams have at least two colors, but not many have a full palette of four,
I decided to limit this clustering analysis to just the primary and secondary colors.

Thus, my cluster analysis takes the following two factors as inputs:
+ hue (`hue`), ranging from 0 to 360; and
+ ordinality (`ord`), either 1 or 2.

With my setup decided upon, I can implement a
a tidy pipeline for statistical analysis--making heavy use of
[David Robinson](http://varianceexplained.org/)'s [{broom} package](https://github.com/tidyverse/broom)--to 
explore various values of k in a kmeans model for the data.
(The package's
[kmeans vignette](https://cran.r-project.org/web/packages/broom/vignettes/kmeans.html)
provides a really helpful example.)

```{r colors_tidy_ord2, echo = FALSE}
colors_tidy_ord2 <-
  colors_tidy %>%
  filter(ord %in% c("primary", "secondary")) %>% 
  tidyr::spread(ord, hex) %>%
  mutate(secondary = ifelse(!is.na(secondary), secondary, primary)) %>% 
  tidyr::gather(ord, hex, primary, secondary)
```

```{r hue_functions, echo = FALSE}
# Reference(s):
# + https://stackoverflow.com/questions/28562288/how-to-use-the-hsl-hue-saturation-lightness-cylindric-color-model
convert_rgb2hsl <- function(r, g, b) {
  val_max <- max(c(r, g, b))
  val_min <- min(c(r, g, b))
  h <- s <- l <- (val_max + val_min) / 2
  if (val_max == val_min){
    h <- s <- 0
  } else {
    d <- val_max - val_min
    s <- ifelse(l > 0.5, d / (2 - val_max - val_min), d / (val_max + val_min))
    if (val_max == r) { h <- (g - b) / d + (ifelse(g < b, 6, 0)) }
    if (val_max == g) { h <- (b - r) / d + 2 }
    if (val_max == b) { h <- (r - g) / d + 4 }
    h <- (h / 6) * 360
  }
  return(c(h=h, s=s, l=l))
}

convert_hex2hsl <- function(hex, unname = FALSE) {
  rgb <- t(grDevices::col2rgb(hex))
  hsl <- convert_rgb2hsl(rgb[1], rgb[2], rgb[3])
  if(unname) {
    hsl <- unname(hsl)
  }
  hsl
}

convert_hex2hue <- function(hex, unname = TRUE) {
  out <- convert_hex2hsl(hex, unname)[1]
}

add_hsl_cols <- function(data) {
  data %>%
    pull(hex) %>%
    purrr::map(convert_hex2hsl) %>% 
    purrr::reduce(rbind) %>% 
    tibble::as_tibble() %>%
    bind_cols(data, .)
}

add_hue_col <- function(data, rename = TRUE) {
  out <-
    data %>%
    pull(hex) %>%
    purrr::map_dbl(convert_hex2hue) %>% 
    tibble::as_tibble() %>%
    bind_cols(data, .)
  
  if(rename) {
    out <-
      out %>% 
      rename(hue = value)
  }
  out
}

```


```{r km_data, echo = FALSE}
km_data <-
  colors_tidy_ord2 %>%
  add_hue_col() %>% 
  select(name, ord, hue) %>% 
  tidyr::spread(ord, hue)
km_data
```

```{r viz_kclusts, echo = FALSE}
seed <- 42
set.seed(seed)

# Reference(s):
# + https://cran.r-project.org/web/packages/broom/vignettes/kmeans.html
# Not sure why, but neither `as.matrix()` nor `rownames<-` eliminates
# warning messages in subsequent actions.
kms <-
  tibble::tibble(k = 1:9) %>%
  group_by(k) %>%
  do(kclust = stats::kmeans(as.matrix(km_data %>% select_if(is.numeric)), .$k)) %>% 
  `rownames<-`(NULL)

kms_clusts <- kms %>% group_by(k) %>% do(broom::tidy(.$kclust[[1]]))
kms_assigns <- kms %>% group_by(k) %>% do(broom::augment(.$kclust[[1]], km_data))
kms_metrics <- kms %>% group_by(k) %>% do(broom::glance(.$kclust[[1]]))

lab_subtitle_kclusts <- paste0("Primary and Secondary Colors", lab_base_suffix)

viz_kclusts <-
  kms_assigns %>% 
  ggplot(aes(x = primary, y = secondary, )) +
  geom_point(aes(color = .cluster), size = 2) +
  geom_point(
    data = kms_clusts %>% 
      rename(primary = x1, secondary = x2), 
    aes(color = cluster), 
    size = 10, 
    shape = 1,
    stroke = 2
  ) +
  teplot::scale_color_te() +
  facet_wrap(~k) +
  viz_theme_base +
  theme(
    # legend.position = "right",
    panel.background = element_rect()
  ) +
  viz_labs_base +
  labs(
    title = "K-Means Clustering for k = 1 to k = 9",
    subtitle =  lab_subtitle_kclusts,
    caption = paste0("64-bit hex values are converted to decimal values",
                     " and are scaled to 0 to 1 range.\n",
                     "Closer to 1 ~ more white and/or strong blend
                     of rgb colors; closer to 0 ~ more black and/or",
                     "strong shade of single one of rgb colors.")
  )
viz_kclusts
```

While this visualization is failry informative, it doesn't quite pinpoint exactly
which value of k is "optimal". There are
[various methods for determining the optimal k-value for a kmeans model]
(http://www.sthda.com/english/articles/29-cluster-validation-essentials/96-determining-the-optimal-number-of-clusters-3-must-know-methods/), 
one of which is the 
["Elbow" method](https://bl.ocks.org/rpgove/0060ff3b656618e9136b).
Basically, the point is to plot the within-cluster sum of squares (WSS) for each
value of k (which is typically monitonically decreasing with increasing k) and
pick the value of k that corresponds to the "bend" in the plot.

```{r viz_wss, echo = FALSE}
labs_x_wss <- seq(2, 8, by = 2)
viz_wss <-
  kms_metrics %>%
  ungroup() %>% 
  mutate(k = as.integer(k)) %>% 
  ggplot(aes(k, tot.withinss)) +
  geom_line() +
  scale_y_continuous(labels = scales::comma_format()) +
  scale_x_continuous(breaks = labs_x_wss, labels = labs_x_wss) +
  teplot::theme_te() +
  labs(
    title = "Total Within-Cluster Sum of Squares Distance for K-Means Algorithm for k = 1 to k = 9",
    subtitle = lab_subtitle_kclusts,
    caption = paste0("The \"elbow\" in the curve indicates where the difference between",
                     "consecutive values of `tot.withinss` is minimized.\n",
                     " This is a generally considered a good choice for `k`",
                     "(This is known as the \"Elbow\" Method).")
  )
viz_wss
```

For those who enjoy calculus, the k value for which the second derivative
of the curve is minimized is the optimal value (by the Elbow method).

```{r kms_metrics}
kms_metrics$tot.withinss[1:8] %>%  diff(differences = 2) %>% which.min() + 2
```

The [`factorextra` package](https://github.com/kassambara/factoextra) has a nice 
function (`fviz_nbclust()`) to summarize
the optimal k value chosen by the consensus of a handful of different methods.

```{r nb_fviz, echo = FALSE}
nb_fviz <-
  factoextra::fviz_nbclust(
    NbClust::NbClust(
      km_data %>% select_if(is.numeric),
      distance = "euclidean",
      min.nc = 2,
      max.nc = 9,
      method = "kmeans"
    ), 
    barfill = "grey50", barcolor = "grey50"
)
nb_fviz
```

It's nice to see that this method comes to the same deduction.

